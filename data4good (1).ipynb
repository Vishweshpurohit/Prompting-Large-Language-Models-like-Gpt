{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "cBS7joNdLiXM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Assuming your data is already loaded into a variable 'data'\n",
        "# Replace this with how you're accessing the JSON data\n",
        "\n",
        "# Convert the data to a list of dictionaries\n",
        "records = [{\"ID\": key, \"Content\": value} for key, value in data.items()]\n",
        "\n",
        "# Create a DataFrame from the list of dictionaries\n",
        "df = pd.DataFrame(records)\n",
        "\n",
        "# Now 'df' contains your data structured in a DataFrame with columns 'ID' and 'Content'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace 'data.csv' with the path to your CSV file\n",
        "df2 = pd.read_csv('/content/test.csv')\n",
        "\n",
        "# Now 'df' contains your CSV data in a DataFrame\n"
      ],
      "metadata": {
        "id": "_b_G6j-lM-y-"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df1 and df2 are your DataFrames\n",
        "print(\"DataFrame 1:\")\n",
        "print(df)\n",
        "\n",
        "print(\"\\nDataFrame 2:\")\n",
        "print(df2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDw_xG_NLjZG",
        "outputId": "44df0c03-5634-46bd-d573-83067cbf2d1a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame 1:\n",
            "        ID                                            Content\n",
            "0     2055  During the visit, I examined Mr. Don Hicks, wh...\n",
            "1      291  During the visit, I examined Tina Will, a 69-y...\n",
            "2      102  D: Good morning Tommie, how can I help you tod...\n",
            "3     2966  D: Good morning, Chris. I understand you've be...\n",
            "4     2438  D: Hi Ernest, I understand you're here for a c...\n",
            "...    ...                                                ...\n",
            "1996  1732  D: ¡Buenos días, Erwin Thompson! Entiendo que ...\n",
            "1997  2193  During the visit, I asked Ms. Diana Griffith a...\n",
            "1998  2833  During the visit, I, the doctor, explained to ...\n",
            "1999  1221  Durin' the vissit, Mildred Favero, aged 93, pr...\n",
            "2000  1284  D: Good morning, Mr. Burns. How can I help you...\n",
            "\n",
            "[2001 rows x 2 columns]\n",
            "\n",
            "DataFrame 2:\n",
            "                                         Id  Transcript  \\\n",
            "0      587d0feb-5780-43e1-9595-e19d4b31dc07        2055   \n",
            "1      263e8884-e8ba-4266-bb0c-85271419a0b3        2055   \n",
            "2      74c68eca-61b2-49d0-9b1c-0f6f886b04ff        2055   \n",
            "3      8572ab5d-f20a-4de5-ab44-f42b07e45a00        2055   \n",
            "4      f5c92075-ef05-4fbf-a7a0-aa86c586ff02        2055   \n",
            "...                                     ...         ...   \n",
            "12001  89f03c30-3b65-4241-9157-9362f56381e6        1284   \n",
            "12002  25bf4a39-edd7-40d5-8c55-9ae5a6fdee08        1284   \n",
            "12003  774a32b8-237d-42f1-9907-d14d27d43858        1284   \n",
            "12004  9fe29c8e-7189-4c47-ab27-c01d61cf39fc        1284   \n",
            "12005  ca6e4182-916f-473e-8d37-2395346afc7c        1284   \n",
            "\n",
            "                                         Question  \n",
            "0                     What is the patient's name?  \n",
            "1                      What is the patient's age?  \n",
            "2                What is the patient's condition?  \n",
            "3      What symptoms is the patient experiencing?  \n",
            "4         What precautions did the doctor advise?  \n",
            "...                                           ...  \n",
            "12001                  What is the patient's age?  \n",
            "12002            What is the patient's condition?  \n",
            "12003  What symptoms is the patient experiencing?  \n",
            "12004     What precautions did the doctor advise?  \n",
            "12005         What drug did the doctor prescribe?  \n",
            "\n",
            "[12006 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df is your DataFrame\n",
        "# Replace 'your_dataframe.csv' with the desired file name for your CSV\n",
        "df.to_csv('your_dataframe.csv', index=False)\n"
      ],
      "metadata": {
        "id": "OI2Y6SPIQSg-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssbkMh2iTYkL",
        "outputId": "51f01dd2-9244-4b99-e4e7-22608564fb35"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import words\n",
        "import nltk\n",
        "\n",
        "# Download the words corpus if you haven't already\n",
        "nltk.download('words')\n",
        "\n",
        "# Assuming df is your DataFrame and 'Content' is the column of interest\n",
        "non_english_rows = df[df['Content'].apply(lambda x: not any(word in words.words() for word in word_tokenize(str(x).lower())))]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "moYk_TK0TEHB",
        "outputId": "76042741-d079-4328-ca30-0b17e0b1bb49"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-31e6697e8cc3>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Assuming df is your DataFrame and 'Content' is the column of interest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mnon_english_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[0;32m-> 4771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-31e6697e8cc3>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Assuming df is your DataFrame and 'Content' is the column of interest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mnon_english_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-31e6697e8cc3>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Assuming df is your DataFrame and 'Content' is the column of interest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mnon_english_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/wordlist.py\u001b[0m in \u001b[0;36mwords\u001b[0;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_lines_startswith\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         return [\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/wordlist.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_lines_startswith\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         ]\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming df is your DataFrame\n",
        "row_35 = df.iloc[1996]  # Indexing in Python starts from 0, so the 35th row has an index of 34\n",
        "\n",
        "print(row_35)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B88pVQwHX0j3",
        "outputId": "05f758b4-4e16-4cb1-97ed-f2983f42268f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID                                                      1732\n",
            "Content    D: ¡Buenos días, Erwin Thompson! Entiendo que ...\n",
            "Name: 1996, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numbers = list(range(36, 1997, 10))\n",
        "print(numbers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbqrH_0IZZM4",
        "outputId": "ca1e8318-f1b2-4863-8067-86b1493431cc"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[36, 46, 56, 66, 76, 86, 96, 106, 116, 126, 136, 146, 156, 166, 176, 186, 196, 206, 216, 226, 236, 246, 256, 266, 276, 286, 296, 306, 316, 326, 336, 346, 356, 366, 376, 386, 396, 406, 416, 426, 436, 446, 456, 466, 476, 486, 496, 506, 516, 526, 536, 546, 556, 566, 576, 586, 596, 606, 616, 626, 636, 646, 656, 666, 676, 686, 696, 706, 716, 726, 736, 746, 756, 766, 776, 786, 796, 806, 816, 826, 836, 846, 856, 866, 876, 886, 896, 906, 916, 926, 936, 946, 956, 966, 976, 986, 996, 1006, 1016, 1026, 1036, 1046, 1056, 1066, 1076, 1086, 1096, 1106, 1116, 1126, 1136, 1146, 1156, 1166, 1176, 1186, 1196, 1206, 1216, 1226, 1236, 1246, 1256, 1266, 1276, 1286, 1296, 1306, 1316, 1326, 1336, 1346, 1356, 1366, 1376, 1386, 1396, 1406, 1416, 1426, 1436, 1446, 1456, 1466, 1476, 1486, 1496, 1506, 1516, 1526, 1536, 1546, 1556, 1566, 1576, 1586, 1596, 1606, 1616, 1626, 1636, 1646, 1656, 1666, 1676, 1686, 1696, 1706, 1716, 1726, 1736, 1746, 1756, 1766, 1776, 1786, 1796, 1806, 1816, 1826, 1836, 1846, 1856, 1866, 1876, 1886, 1896, 1906, 1916, 1926, 1936, 1946, 1956, 1966, 1976, 1986, 1996]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#getting all the rows with data in a different language import pandas as pd\n",
        "\n",
        "# Assuming df is your original DataFrame\n",
        "\n",
        "# List of row indices to extract\n",
        "row_indices = list(range(6, 1997, 10))  # This generates the list of rows you specified\n",
        "\n",
        "# Extract rows with the specified indices and select 'ID' and 'Content' columns\n",
        "new_df = df.iloc[row_indices][['ID', 'Content']]\n",
        "print(new_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge6KOHhOab2o",
        "outputId": "9019f03d-4cbb-41e2-d618-1f92376fbb3e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ID                                            Content\n",
            "6     3538  D: शुभ प्रभात, थॉमस जी। आज मुझे आपकी कैसे सहाय...\n",
            "16    2340  D: صباح الخير، السيدة Godwin. أنا أفهم أنك تتع...\n",
            "26    4580  D: शुभ सुहावनी डेनिस, मैं डॉ॰ स्मिथ हूँ। आप आज...\n",
            "36    2500  D: Good morning Christopher. How can I help yo...\n",
            "46    2131  During the visit, I, the doctor, examined Mr. ...\n",
            "...    ...                                                ...\n",
            "1956  3492  D: Good morning, Dauni ji.I understand that yo...\n",
            "1966   707  During the visit, I was the doctor, I listened...\n",
            "1976   586  D: Good morning, Joan, how do you feel today?\\...\n",
            "1986  2468  D: Good morning Philip, I am Doctor Smith.My n...\n",
            "1996  4654  D: Hello, Robert.how do you feel today?\\nP: He...\n",
            "\n",
            "[200 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install googletrans==4.0.0-rc1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "BSKyfGNjarMc",
        "outputId": "ffea906f-f9fa-41a8-bf4f-4c8a40b791a0"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-76-1c1cd21c647c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install googletrans==4.0.0-rc1\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "import pandas as pd\n",
        "\n",
        "# Function to translate text to English\n",
        "def translate_to_english(text):\n",
        "    translator = Translator()\n",
        "    translation = translator.translate(text, dest='en')\n",
        "    return translation.text\n",
        "\n",
        "# Assuming new_df is your DataFrame with non-English content in the 'Content' column\n",
        "new_df['Content'] = new_df['Content'].apply(translate_to_english)\n"
      ],
      "metadata": {
        "id": "ADhH-Mr5a8My"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_df)\n",
        "new_df.to_csv('translated_data4good.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlYppwVtbS4e",
        "outputId": "05546687-2dde-4ebe-e60a-f874b660c228"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ID                                            Content\n",
            "6     3538  D: Good morning, Thomas ji.How can I help you ...\n",
            "16    2340  D: Good morning, Godwin.I understand that you ...\n",
            "26    4580  D: Auspicious pleasant Denis, I am Dr. Smith.H...\n",
            "36    2500  D: Good morning Christopher. How can I help yo...\n",
            "46    2131  During the visit, I, the doctor, examined Mr. ...\n",
            "...    ...                                                ...\n",
            "1956  3492  D: Good morning, Dauni ji.I understand that yo...\n",
            "1966   707  During the visit, I was the doctor, I listened...\n",
            "1976   586  D: Good morning, Joan, how do you feel today?\\...\n",
            "1986  2468  D: Good morning Philip, I am Doctor Smith.My n...\n",
            "1996  4654  D: Hello, Robert.how do you feel today?\\nP: He...\n",
            "\n",
            "[200 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df is your original DataFrame\n",
        "numbers = list(range(6, 1997, 10))  # List of column numbers to be removed\n",
        "\n",
        "# Ensure that the column numbers are within the DataFrame's range\n",
        "numbers = [col for col in numbers if col < len(df.columns)]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NVtRtpErbs5U"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Drop columns based on their numerical position\n",
        "df = df.drop(df.columns[36])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "RMIkrJlegjl1",
        "outputId": "188064f7-72fe-4f7b-b382-3084dcb04601"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-f0bbeb74509c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Drop columns based on their numerical position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m36\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5318\u001b[0m             \u001b[0;31m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5319\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 36 is out of bounds for axis 0 with size 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq1XM_WYg6sU",
        "outputId": "3e011779-6366-4975-bd96-8455049993f0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ID                                            Content\n",
            "0     2055  During the visit, I examined Mr. Don Hicks, wh...\n",
            "1      291  During the visit, I examined Tina Will, a 69-y...\n",
            "2      102  D: Good morning Tommie, how can I help you tod...\n",
            "3     2966  D: Good morning, Chris. I understand you've be...\n",
            "4     2438  D: Hi Ernest, I understand you're here for a c...\n",
            "...    ...                                                ...\n",
            "2193  4654  D: Hello, Robert.how do you feel today?\\nP: He...\n",
            "2194  1974  D: Hello, Deborah.How can I help you today?\\nP...\n",
            "2195  2699  During the visit, examine Don Theodore Hems, 7...\n",
            "2196  4195  During the visit, I evaluated Miss Lori Batis,...\n",
            "2197  1732  D: Good morning, Erwin Thompson!I understand t...\n",
            "\n",
            "[2198 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'ID' is the column name for IDs in both DataFrames\n",
        "\n",
        "# Extract IDs from 'new_df'\n",
        "ids_to_drop = new_df['ID']\n",
        "\n",
        "# Drop rows from df based on matching 'ID' values\n",
        "df = df[~df['ID'].isin(ids_to_drop)]\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwLo2Lgzhup5",
        "outputId": "237ad192-b8ab-4a86-b45f-585d53192d0e"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ID                                            Content\n",
            "0     2055  During the visit, I examined Mr. Don Hicks, wh...\n",
            "1      291  During the visit, I examined Tina Will, a 69-y...\n",
            "2      102  D: Good morning Tommie, how can I help you tod...\n",
            "3     2966  D: Good morning, Chris. I understand you've be...\n",
            "4     2438  D: Hi Ernest, I understand you're here for a c...\n",
            "...    ...                                                ...\n",
            "2192  1555  I revealed during a journey with a 79 -year -o...\n",
            "2194  1974  D: Hello, Deborah.How can I help you today?\\nP...\n",
            "2195  2699  During the visit, examine Don Theodore Hems, 7...\n",
            "2196  4195  During the visit, I evaluated Miss Lori Batis,...\n",
            "2197  1732  D: Good morning, Erwin Thompson!I understand t...\n",
            "\n",
            "[1978 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate new_df to df\n",
        "df = pd.concat([df, new_df], ignore_index=True)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI0e7SPMi3IM",
        "outputId": "4e9336ea-b16b-45a2-8503-d60ea201c015"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ID                                            Content\n",
            "0     2055  During the visit, I examined Mr. Don Hicks, wh...\n",
            "1      291  During the visit, I examined Tina Will, a 69-y...\n",
            "2      102  D: Good morning Tommie, how can I help you tod...\n",
            "3     2966  D: Good morning, Chris. I understand you've be...\n",
            "4     2438  D: Hi Ernest, I understand you're here for a c...\n",
            "...    ...                                                ...\n",
            "2173  3492  D: Good morning, Dauni ji.I understand that yo...\n",
            "2174   707  During the visit, I was the doctor, I listened...\n",
            "2175   586  D: Good morning, Joan, how do you feel today?\\...\n",
            "2176  2468  D: Good morning Philip, I am Doctor Smith.My n...\n",
            "2177  4654  D: Hello, Robert.how do you feel today?\\nP: He...\n",
            "\n",
            "[2178 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now we have starting dataset but with mostly in english\n",
        "df.to_csv('mostly_in_english2.csv', index=False)"
      ],
      "metadata": {
        "id": "cudFPrnhjGak"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wjgi5oJ1mnlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aXSmlYkDlbP8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}